{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "sys.path.append('../tests/python-support/')\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import experiments\n",
    "import itertools\n",
    "import util\n",
    "import numpy as np\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Whether to only run the offline part of the experiment,\n",
    "# or both offline and online\n",
    "offline_only = False\n",
    "\n",
    "# Whether to import/export homogenized basis\n",
    "import_basis = True\n",
    "export_basis = False\n",
    "\n",
    "# Names of experiments to run\n",
    "experiment_names = [ \"homogenized_l_shaped_amg\" ]\n",
    "\n",
    "# Offline parameters. \n",
    "# Use integer exponents so that we can have reliable filenames\n",
    "h_base = 0.5\n",
    "h_exponent = [ 5, 6 ]\n",
    "oversampling = [ 2 ]\n",
    "dense_fallback_threshold = [ 300 ]\n",
    "\n",
    "# Online parameters\n",
    "end_time = [0.01]\n",
    "sample_count = [ 101 ]\n",
    "integrator = [ \"iterative_leapfrog\" ]\n",
    "use_coarse_rhs = [ False ]\n",
    "use_coarse_mass_matrix = [ True, False ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_offline_param(h_exponent, oversampling, threshold):\n",
    "    p = {\n",
    "        'mesh_resolution': h_base ** h_exponent,\n",
    "        'oversampling': oversampling,\n",
    "        'dense_fallback_threshold': threshold\n",
    "    }\n",
    "    basis_file = 'basis_{}_{}.h5'.format(h_exponent, oversampling)\n",
    "    if import_basis:\n",
    "        p['basis_import_file'] = basis_file\n",
    "    if export_basis:\n",
    "        p['basis_export_file'] = basis_file\n",
    "    return p\n",
    "\n",
    "def make_online_param(end_time, sample_count, integrator, use_coarse_rhs, use_coarse_mass_matrix):\n",
    "    return {\n",
    "        'end_time': end_time,\n",
    "        'sample_count': sample_count,\n",
    "        'integrator': integrator,\n",
    "        'load_quadrature_strength': 2,\n",
    "        'use_coarse_rhs': use_coarse_rhs,\n",
    "        'use_coarse_mass_matrix': use_coarse_mass_matrix\n",
    "    }\n",
    "\n",
    "def aggregate_offline_params():\n",
    "    offline_param_product = itertools.product(h_exponent, oversampling, dense_fallback_threshold)\n",
    "    return [ make_offline_param(h_exp, ovs, threshold) for (h_exp, ovs, threshold) in offline_param_product]\n",
    "\n",
    "def aggregate_online_params():\n",
    "    online_param_product = itertools.product(end_time, sample_count, \n",
    "                                             integrator, use_coarse_rhs, use_coarse_mass_matrix)\n",
    "    return [ make_online_param(e, s, i, rhs, mm) for (e, s, i, rhs, mm) in online_param_product ]\n",
    "\n",
    "def aggregate_input():\n",
    "    offline_params = aggregate_offline_params()\n",
    "    online_params = aggregate_online_params()\n",
    "    if offline_only:\n",
    "        return [{ \n",
    "                    'experiment': experiment,\n",
    "                    'offline': offline\n",
    "                }\n",
    "                for (experiment, offline) \n",
    "                in itertools.product(experiment_names, offline_params)\n",
    "               ]\n",
    "    else:\n",
    "        return [{ \n",
    "                    'experiment': experiment,\n",
    "                    'offline': offline,\n",
    "                    'online': online \n",
    "                }\n",
    "                for (experiment, offline, online) \n",
    "                in itertools.product(experiment_names, offline_params, online_params)\n",
    "               ]\n",
    "    \n",
    "\n",
    "experiment_input = aggregate_input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run experiments and collect results\n",
    "results = experiments.run_experiments(experiment_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Uncomment to inspect raw results\n",
    "pprint(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def is_successful(result):\n",
    "    return 'error' not in result\n",
    "\n",
    "def key(experiment):\n",
    "    name = experiment['experiment']\n",
    "    offline_params = experiment['offline']['parameters']\n",
    "    oversampling = offline_params['oversampling']\n",
    "    if offline_only:\n",
    "        return (name, \"no integration\", oversampling)\n",
    "    else:\n",
    "        online_params = experiment['online']['parameters']\n",
    "        integrator = online_params['integrator']\n",
    "        use_coarse_rhs = online_params['use_coarse_rhs']\n",
    "        use_coarse_mass_matrix = online_params['use_coarse_mass_matrix']\n",
    "        return (name, integrator, oversampling, use_coarse_rhs, use_coarse_mass_matrix)\n",
    "    \n",
    "\n",
    "\n",
    "def flatten_timing(timing):\n",
    "    flattened_timing = defaultdict(list)\n",
    "    for experiment_timing in timing:\n",
    "        for k, v in experiment_timing.items():\n",
    "            flattened_timing[k].append(v)\n",
    "    return flattened_timing\n",
    "\n",
    "def print_timing(flattened_timing):\n",
    "    timing_pad = len(max(flattened_timing.keys(), key = lambda s: len(s)))\n",
    "\n",
    "    for timing_name, values in sorted(flattened_timing.items(), key=lambda pair: pair[0]):\n",
    "        padded_name = str(\"{}:\".format(timing_name).ljust(timing_pad + 1))\n",
    "        formatted_values = \", \".join([ \"{:10.4g}\".format(val) for val in values])\n",
    "        print(\"{} [ {} ]\".format(padded_name, formatted_values))\n",
    "\n",
    "success_results = [ result for result in results if is_successful(result) ]\n",
    "failure_results = [ result for result in results if not is_successful(result) ]\n",
    "success_results = sorted(success_results, key = key)\n",
    "grouped_results = itertools.groupby(success_results, key = key)\n",
    "for (name, integrator, oversampling, use_coarse_rhs, use_coarse_mass_matrix), result in grouped_results:\n",
    "    result = list(result)\n",
    "    offline_results = [ result['offline']['result'] for result in result ]\n",
    "    coarse_dof = [ result['mesh_details']['num_coarse_vertices'] for result in offline_results ]\n",
    "    fine_dof = [ result['mesh_details']['num_fine_vertices'] for result in offline_results ]\n",
    "    \n",
    "    offline_timings = [ result['offline']['result']['timing'] for result in result ]\n",
    "    offline_timings = flatten_timing(offline_timings)\n",
    "    \n",
    "    print(\"=============================================\")\n",
    "    print(\"Experiment name: {name}\".format(name=name))\n",
    "    print(\"Integrator:      {}\".format(integrator))\n",
    "    print(\"Oversampling:    {}\".format(oversampling))\n",
    "    print(\"Use coarse rhs:  {}\".format(use_coarse_rhs))\n",
    "    print(\"Use coarse mass: {}\".format(use_coarse_mass_matrix))\n",
    "    print(\"Coarse dof:      {}\".format(coarse_dof))\n",
    "    print(\"Fine dof:        {}\".format(fine_dof))\n",
    "    \n",
    "    if not offline_only:\n",
    "        online_results = [ result['online']['result'] for result in result ]\n",
    "        l2_error = [ result['error_summary']['l2'] for result in online_results ]\n",
    "        h1_error = [ result['error_summary']['h1'] for result in online_results ]\n",
    "        h1_semi_error = [ result['error_summary']['h1_semi'] for result in online_results ]\n",
    "        l2_coarse_slope = util.estimate_slope(coarse_dof, l2_error)\n",
    "        h1_coarse_slope = util.estimate_slope(coarse_dof, h1_error)\n",
    "        l2_fine_slope = util.estimate_slope(fine_dof, l2_error)\n",
    "        h1_fine_slope = util.estimate_slope(fine_dof, h1_error)\n",
    "        \n",
    "        online_timings = [ result['online']['result']['timing'] for result in result ]\n",
    "        online_timings = flatten_timing(online_timings)\n",
    "        print(\"H1 semi:  {}\".format(h1_semi_error))\n",
    "        print(\"H1:       {}\".format(h1_error))\n",
    "        print(\"L2:       {}\".format(l2_error))\n",
    "        print(\"\")\n",
    "        print(\"H1 coarse slope: {}\".format(h1_coarse_slope))\n",
    "        print(\"L2 coarse slope: {}\".format(l2_coarse_slope))\n",
    "        print(\"H1 fine slope:   {}\".format(h1_fine_slope))\n",
    "        print(\"L2 fine slope:   {}\".format(l2_fine_slope))\n",
    "        print(\"\")\n",
    "        print(\"Timing (online):\")\n",
    "        print(\"---------------------------------------------\")\n",
    "        print_timing(online_timings)\n",
    "\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"Timing (offline):\")\n",
    "    print(\"---------------------------------------------\")\n",
    "    print_timing(offline_timings)\n",
    "    print(\"=============================================\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Offline statistics summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def visualize_statistics(summary):\n",
    "    for name, summary in summary.items():\n",
    "        histogram = summary['distribution']\n",
    "        groups = np.arange(0, len(histogram))\n",
    "        proportions = [ entry['accumulated'] for entry in histogram ]\n",
    "        plt.figure()\n",
    "        plt.title(\"{}\".format(name))\n",
    "        plt.bar(groups, proportions)\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "\n",
    "grouped_results = itertools.groupby(success_results, key = key)\n",
    "for (name, integrator, oversampling), result in grouped_results:\n",
    "    offline_results = [ result['offline']['result'] for result in result ]\n",
    "    coarse_dof = [ result['mesh_details']['num_coarse_vertices'] for result in offline_results ]\n",
    "    fine_dof = [ result['mesh_details']['num_fine_vertices'] for result in offline_results ]  \n",
    "    \n",
    "    print(\"=============================================\")\n",
    "    print(\"Experiment name: {name}\".format(name=name))\n",
    "    print(\"Oversampling:    {}\".format(oversampling))\n",
    "    print(\"Coarse dof:      {}\".format(coarse_dof))\n",
    "    print(\"Fine dof:        {}\".format(fine_dof))\n",
    "    \n",
    "    for statistic in [ result['stats'] for result in offline_results ]:\n",
    "        for name, summary in statistic.items():\n",
    "#             print(\"{} max: {}\".format(name, summary['max']))\n",
    "#             print(\"{} median: {}\".format(name, summary['median']))\n",
    "#             print(\"{} mean: {}\".format(name, summary['mean']))\n",
    "             pprint(summary['distribution'])\n",
    "        visualize_statistics(statistic)\n",
    "    \n",
    "    print(\"=============================================\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

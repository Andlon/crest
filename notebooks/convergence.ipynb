{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "sys.path.append('../tests/python-support/')\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import experiments\n",
    "import itertools\n",
    "import util\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Whether to only run the offline part of the experiment,\n",
    "# or both offline and online\n",
    "offline_only = False\n",
    "\n",
    "# Whether to import/export homogenized basis\n",
    "import_basis = True\n",
    "export_basis = False\n",
    "\n",
    "# Names of experiments to run\n",
    "experiment_names = [ \"homogenized_l_shaped\" ]\n",
    "\n",
    "# Offline parameters. \n",
    "# Use integer exponents so that we can have reliable filenames\n",
    "h_base = 0.5\n",
    "h_exponent = [2, 3, 4]\n",
    "oversampling = [ 2 ]\n",
    "\n",
    "# Online parameters\n",
    "end_time = [0.5]\n",
    "sample_count = [ 401 ]\n",
    "integrator = [ \"lumped_leapfrog\", \"iterative_leapfrog\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_offline_param(h_exponent, oversampling):\n",
    "    p = {\n",
    "        'mesh_resolution': h_base ** h_exponent,\n",
    "        'oversampling': oversampling\n",
    "    }\n",
    "    basis_file = 'basis_{}_{}.h5'.format(h_exponent, oversampling)\n",
    "    if import_basis:\n",
    "        p['basis_import_file'] = basis_file\n",
    "    if export_basis:\n",
    "        p['basis_export_file'] = basis_file\n",
    "    return p\n",
    "\n",
    "def make_online_param(end_time, sample_count, integrator):\n",
    "    return {\n",
    "        'end_time': end_time,\n",
    "        'sample_count': sample_count,\n",
    "        'integrator': integrator\n",
    "    }\n",
    "\n",
    "def aggregate_offline_params():\n",
    "    offline_param_product = itertools.product(h_exponent, oversampling)\n",
    "    return [ make_offline_param(h_exp, ovs) for (h_exp, ovs) in offline_param_product]\n",
    "\n",
    "def aggregate_online_params():\n",
    "    online_param_product = itertools.product(end_time, sample_count, integrator)\n",
    "    return [ make_online_param(e, s, i) for (e, s, i) in online_param_product ]\n",
    "\n",
    "def aggregate_input():\n",
    "    offline_params = aggregate_offline_params()\n",
    "    online_params = aggregate_online_params()\n",
    "    if offline_only:\n",
    "        return [{ \n",
    "                    'experiment': experiment,\n",
    "                    'offline': offline\n",
    "                }\n",
    "                for (experiment, offline) \n",
    "                in itertools.product(experiment_names, offline_params)\n",
    "               ]\n",
    "    else:\n",
    "        return [{ \n",
    "                    'experiment': experiment,\n",
    "                    'offline': offline,\n",
    "                    'online': online \n",
    "                }\n",
    "                for (experiment, offline, online) \n",
    "                in itertools.product(experiment_names, offline_params, online_params)\n",
    "               ]\n",
    "    \n",
    "\n",
    "experiment_input = aggregate_input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run experiments and collect results\n",
    "results = experiments.run_experiments(experiment_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Uncomment to inspect raw results\n",
    "pprint(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of online results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def is_successful(result):\n",
    "    return 'error' not in result\n",
    "\n",
    "def key(experiment):\n",
    "    name = experiment['experiment']\n",
    "    offline_params = experiment['offline']['parameters']\n",
    "    online_params = experiment['online']['parameters']\n",
    "    integrator = online_params['integrator']\n",
    "    oversampling = offline_params['oversampling']\n",
    "    return (name, integrator, oversampling)\n",
    "\n",
    "success_results = [ result for result in results if is_successful(result) ]\n",
    "failure_results = [ result for result in results if not is_successful(result) ]\n",
    "\n",
    "# TODO: Distinguish failures\n",
    "\n",
    "if not offline_only:\n",
    "    success_results = sorted(success_results, key = key)\n",
    "    grouped_results = itertools.groupby(success_results, key = key)\n",
    "    for (name, integrator, oversampling), result in grouped_results:\n",
    "        result = list(result)\n",
    "        offline_results = [ result['offline']['result'] for result in result ]\n",
    "        online_results = [ result['online']['result'] for result in result ]\n",
    "        num_dof = [ result['mesh_details']['num_vertices'] for result in offline_results ]\n",
    "        l2_error = [ result['error_summary']['l2'] for result in online_results ]\n",
    "        h1_error = [ result['error_summary']['h1'] for result in online_results ]\n",
    "        h1_semi_error = [ result['error_summary']['h1_semi'] for result in online_results ]\n",
    "        l2_slope = util.estimate_slope(num_dof, l2_error)\n",
    "        h1_slope = util.estimate_slope(num_dof, h1_error)\n",
    "        \n",
    "        online_timings = [ result['online']['result']['timing'] for result in result ]\n",
    "        flattened_timing = defaultdict(list)\n",
    "        for experiment_timing in online_timings:\n",
    "            for k, v in experiment_timing.items():\n",
    "                flattened_timing[k].append(v)\n",
    "        timing_pad = len(max(flattened_timing.keys(), key = lambda s: len(s)))\n",
    "\n",
    "        print(\"=============================================\")\n",
    "        print(\"Experiment name: {name}\".format(name=name))\n",
    "        print(\"Integrator:      {}\".format(integrator))\n",
    "        print(\"Oversampling:    {}\".format(oversampling))\n",
    "        print(\"Dof:      {}\".format(num_dof))\n",
    "        print(\"H1 semi:  {}\".format(h1_semi_error))\n",
    "        print(\"H1:       {}\".format(h1_error))\n",
    "        print(\"L2:       {}\".format(l2_error))\n",
    "        print(\"H1 slope: {}\".format(h1_slope))\n",
    "        print(\"L2 slope: {}\".format(l2_slope))\n",
    "        print(\"\")\n",
    "        print(\"Timing:\")\n",
    "        print(\"---------------------------------------------\")\n",
    "        for timing_name, values in flattened_timing.items():\n",
    "            padded_name = str(\"{}:\".format(timing_name).ljust(timing_pad + 1))\n",
    "            formatted_values = \", \".join([ \"{:10.4g}\".format(val) for val in values])\n",
    "            print(\"{} [ {} ]\".format(padded_name, formatted_values))\n",
    "        \n",
    "    \n",
    "        print(\"=============================================\")\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
